# Relatório de Estudos

**Nome do Estagiário:** Guilherme Camargo Silva  
**Data:** 09/08/2024

**Módulos/Etapas Feitas:**  
1. **Linguagens e Frameworks**
2. **Mensageria**
3. **Virtualização** 
4. **Computação em Nuvem**

## Resumo dos módulos 

### Linguagens e Frameworks

#### Python

Python é uma linguagem de alto nível reconhecida por sua simplicidade e legibilidade.

Características:
- Sintaxe simples: linguagem fácil de ler e escrever.
- Interpretação: Python pode ser executado em diferentes plataformas sem a necessidade de recompilação.
- Bibliotecas e frameworks: possui uma coleção de bibliotecas e frameworks que atuam no desenvolvimento de diferentes aplicações.

Usos:
- Desenvolvimento Web.
- Data Science e Machine Learning.
- Automação e Scripting.
- Desenvolvimento de Software.
- Inteligência Artificial.
- Deep Learning.
- Computação científica e pesquisa.
- Desenvolvimento de jogos.
- Desenvolvimento de aplicativos desktop.

#### Apache Spark

É um framework de processamento de dados open-source para processamento rápido. Possui capacidade de processar grandes volumes de dados com um desempenho mais rápido. O PySpark serve como interface do Apache Spark para utilização do Python.

Características:
- Processamento em memória.
- API para diferentes tipos de análise.
- Escalabilidade e distribuição.
- Integração.

O Apache Spark pode ser utilizado em aplicações de análises em tempo real, Machine Learning, ETL e processamento de grafos.

Benefícios:
- Desempenho devido sua otimização em processos rápidos.
- Versatilidade no suporte de diferentes linguagens e aplicações.
- Facilidade ao utilizar as bibliotecas Python.
- Contribuição da comunidade.

#### Apache Beam

É um modelo de processamento de dados em lote em tempo real. Pemite execução de pipelines de dados independente do ambiente de execução.
- Unificado: modelo unificado para processamento.
- Portabilidade: pipelines podem ser executadas em diferentes sistemas de execução.
- Flexível: suporte para várias linguagens.
- Transformações: possui um conjunto de transformações para manipulação de dados.
- Janelas/Watermarks: suporte para processamento de eventos em tempo real.

Pode ser utilizado em ETL, processamento em tempo real, agregações e análises.

#### Google Dataflow

É uma plataforma de processamento de dados em lote e streaming gerenciado pelo Google Cloud. Realiza o processamento de dados e lote e em streaming. O Google Dataflow não necessita de gerenciamento de escalabilidade, balanceamento ou manutenção.

Possui integração com outros serviços do Google Cloud: BigQuery, Cloud Storage e Pub/Sub. Oferece juntamente monitoramento e visualização de pipelines. O custo gerado é baseado no processamento e volume de dados.

#### Apache Airflow

É uma plataforma de orquestração e automação de workflows de dados. Utiliza Python para definir workflows na criação de DAGs (Directed Acylic Graphs) para ordem e lógica de tarefas. Oferece interface web para os processos de monitoramento e gerenciamento. Suporta agendamento de tarefas para execução dos workflows.

A execução é realizada de forma paralela para lidar com grandes volumes de dados presentes. Possui um retry automático em caso de falhas dos workflows. Possui integração com outros serviços (banco de dados, serviços de nuvem e APIs).

Componentes:
1. DAG: representação do relacionamento das tarefas e ordem de execução.
2. Operadores: componentes que definem as ações que são realizadas em cada tarefa.
3. Tasks: unidade de tarefa.
4. Scheduler: acionamento de tarefas de acordo com um cronograma existente.
5. Executor: lida com a execução das tarefas.
6. Web Interface: intreface gráfica para gerenciar os processos das tarefas e suas execuções.

### Mensageria

Conceito de troca de mensagens entre componentes ou sistemas de maneira assíncrona e desacoplada. As unidades de dados que são transmitidos são mensagens sendo dois tipos: payload (dados reais) e metadados (informações adicionais). A transmissão de mensagens é feita por meio de publicadores e assinantes, onde o publicador envia mensagens em tópicos que são os locais onde as mensagens são publicadas e o assinante visualiza essas mensagens de acordo com o tópico que inscreveu-se.

O envio das mensagens ficam guardados em filas pois elas esperam a leitura dos seus assinantes. A comunicação é realizada pelo Broker de mensagens que gerencia o envio e recebimento no destino correto.

Possui desacoplamento, sendo assim não há preocupação com o estado do destino, somente envia a mensagem. O remetente também é assíncrono, não parando suas atividades para esperar uma resposta do destinatário.

Tipos de mensageria:
- Pub/Sub: publicador envia mensagens para um tópico e os assinantes podem receber essas mensagens.
- Fila de mensagens: as mensagens são mantidas em fila para processamento pelos consumidores.
- Ponto a ponto: comunicação realizada de forma direta sem intermediários durante o trajeto.

Características:

- Os sistemas envolvidos nesse trajeto operam de forma independente.
- Em caso de falhas nas mensagens elas podem ser reprocessadas. 
- Pode realizar escalabilidade de componentes sem afetar os processos. 
- Possui flexibilidade na utilização de sistemas e aplicações.
- Pode melhorar o desempenho pela forma assíncrona e distribuição de carga.

Exemplos:

RabbitMQ, Apache Kafka, Google Cloud Pub/Sub, Apache ActiveMQ.

#### Google Cloud Pub/Sub

É um serviço de mensageria para facilitar o envio e recebimento de serviços. Os publicadores enviam mensagens para tópicos que podem ser acessadas pelos consumidores que recebem mensagens dos tópicos.

Possui escalabilidade automática, se ajustando de acordo com o volume de mensagens e assinantes. Possui baixa latência e alta disponibilidade para o processo de envio e recebimento. As mensagens são armazenadas até o processo de consumo por assinantes.

### Virtualização

Máquinas virtuais (VMs) são emulações de máquinas físicas em um ambiente de software que permite várias execuções em um hardware físico.

Características:
- Isolamento: cada máquina virtual executam diferentes sistemas sem interferência entre si.

- Recursos compartilhados: máquinas virtuais compartilham recursos físicos (CPU, memória e armazenamento).

- Portabilidade: podem ser movidas entre servidores físicos.

- Escalabilidade: escalam aplicações de acordo com demandas.

Gerenciamento simplificado: centralização e automatização no gerenciamento de máquinas virtuais.

Componentes:

- Hypervisor: software que cria e gerencia as máquinas virtuais: Bare-metal que executa no hardware do servidor e Hosted em um sistema operacional host.

- Imagens de máquina virtual: arquivos que contêm o sistema da máquina virtual para sua iniciação e operação.

- Virtualização de HardWare: emulam os recursos de hardware para as máquinas virtuais.

- Recursos virtuais: são alocados de acordo com a necessidade.

#### Docker

Plataforma de criação, distribuição e execução em containers que são ambientes isolados com os recursos para que uma aplicação seja executada mesmo em diferentes ambientes.

Containers: armazenam a aplicação em ambiente isolado de forma independente.

Imagens Docker: modelo para criar os containers como código, bibliotecas e dependências.

Dockerfile: instruções para construção de imagem Docker.

Docker Hub: armazenamento e compartilhamento de imagens Docker.

Docker Compose: ferramenta para definir e gerenciar aplicações multi-container.

#### Kubernetes

É uma plataforma de orquestração de containers para automatização de implantação, dimensionamento e operações em containers.

O gerenciamento dos containers é realizado em clusters, realizando implantação, atualização, balanceamento de carga e recuperação. A escalabilidade é realizada automaticamente tanto de forma horizontal e vertical.

Componentes:

- Pod: menor implementação do Kubernetes onde um ou mais containers compartilham o armazenamento e rede.
- Node: máquina que executa os Pods e tem os recursos para realização dos containers.
- Cluster: grupo de nodes que executam juntos as aplicações dos containers.
- Master Node: nó central que coordena o cluster e gerencia a comunicação entre Nodes e Pods.
- Deployment: definição de execução e gerenciamento.
- Service: define os Pods como uma rede para a comunicação entre eles e os meios externos.
- ConfigMap e Secret: separa as configurações e dados sensíveis dos containers.
- Ingress: gerencia o acesso aos serviços dentro do cluster.

Casos de uso:

- Ideal para usos de microserviços onde podem ser realizados em containers separados e coordenados.
- Aplicações altamente escaláveis que podem ser ajustadas com base na demanda.
- Suporta integração contínua, podendo receber atualizações frequentes das aplicações
- Facilita a execução de aplicações multi-clouds e híbridos.
- Controle eficiente dos recursos alocados e configurações, auxiliando na eficiência e segurança.

### Computação em Nuvem

#### Google Cloud Dataflow

É um serviço para o processamento e análise de dados em larga escala pela Google Cloud Platform. Executa pipelines de dados em tempo real em forma de batchs eficientes e escalável. Ele gerencia automaticamente os recursos necessários para as pipelines como a escalabilidade e  alocação de recursos de acordo com a demanda.

Esse serviço se integra com outros serviços do Google Cloud como o BigQuery, Cloud Storage e Pub/Sub. Oferece juntamente uma interface para monitorar pipelines, métricas, logs e problemas.

Componentes:

- Pipeline: fluxo de dados de entrada e de saída.
- Transformações: operações realizadas nos dados como filtragem, agregação e junção de dados.
- PCollections: conjuntos de dados processados em uma pipeline.
- Data Sources e Sinks: Data Sources são a origem de onde os dados são recebidos e os Sinks são os locais de destino dos dados para armazenamento ou utilização.
- Workers: executam as tarefas de processamento que ocorrem nas pipelines.

#### Google Cloud Dataproc

É um serviço para processamento de dados que utiliza Apache Hadoop e Apache Spark. Serve para execução de processamento de dados, análise e machine learning. O Dataproc gerencia os clusters desde sua criação e funcionamento.

Ele integra com outros serviços do Google Cloud (BigQuery, Cloud Storage e Pub/Sub). Ele possui escalabilidade automática dos clusters para atender demandas de trabalho. A eficiência de custos existe devido as execuções de clusters serem realizados somente quando existe demanda.

Suporta diferentes frameworks de processamento de dados como Apache Hadoop, Apache Spark, Apache Hive e Apache HBase. Oferece juntamente ferramentas de monitoramento dos clusters e logs de execução.

#### Google Cloud Composer

Ferramenta de orquestração de workflows do Google Cloud Platform baseado em Apache Airflow. Possui gerenciamento automatizado para provisionamento, escalabilidade e manutenção do ambiente de execução. Possui interface gráfica web para visualização e monitoramento dos workflows.

#### Google Cloud Functions

Serviço do Google Cloud Platform que permite execução de códigos em resposta de eventos em tempo real para funções específicas. O custo é baseado no número de execuções e tempo de atividade.

Não possui necessidade de gerenciamento de infraestrutura, possibilitando somente atenção ao código. Escala automaticamente com base na demanda existente de execução de eventos.

- Funções: códigos que são executados em resposta aos eventos em forma de diferentes linguagens suportadas.

- Gatilhos (Triggers): eventos que acionam uma função de código.

- Eventos: dados transmitidos com o gatilho e recebidos pela função.

- Ambiente de execução: apresenta dados de tempo de execução e os recursos para execução.

- Configurações de funções: definição de variáveis de ambiente, permissões e configurações para realização da função.

## Links de Laboratórios (se houver)

- [Google Colab](https://colab.research.google.com/drive/1oB9G4pFuX4w1LUfF31srQbbZWA4YfnHS?usp=sharing)

**Recursos Utilizados:**
- [Linguagens e Frameworks](https://github.com/2RP-Squad404/Data_Science/blob/main/wiki/subpages/linguagens_frameworks.md)
- [Introdução ao python](https://www.youtube.com/watch?v=rfscVS0vtbw)
- [Mensageria](https://github.com/2RP-Squad404/Data_Science/blob/main/wiki/subpages/mensageria.md)
- [Pub/Sub](https://cloud.google.com/pubsub/docs/overview?hl=pt-br)
- [Virtualização](https://github.com/2RP-Squad404/Data_Science/blob/main/wiki/subpages/virtualizacao.md)
- [Introdução a VM’s](https://azure.microsoft.com/pt-br/resources/cloud-computing-dictionary/what-is-a-virtual-machine)
- [Computação em Nuvem](https://github.com/2RP-Squad404/Data_Science/blob/main/wiki/subpages/computacao_em_nuvem.md)
- [Dataflow](https://cloud.google.com/dataflow/docs/overview?hl=pt-br)
- [Dataproc](https://cloud.google.com/dataproc-serverless/docs?hl=pt-br)
- [Cloud Composer](https://cloud.google.com/docs?hl=pt-br)
- [Cloud function](https://cloud.google.com/functions?hl=pt_br)

**Principais comandos: (se aplicável)**  
```
Variables and data types
character_name = "John"
character_age = 50
isMale = True
print("There once was a man named George, ")
print("he was 70 years old. ")
print("He really liked the name George, ")
print("but didn't like being 70.")
print("There once was a man named", character_name, ",")
print("he was", character_age, "years old. ")
character_name = "Tom"
print("He really liked the name", character_name, ",")
print("but didn't like being", character_age)
```

```
# Inputs
name = input("Enter your name: ")
age = input("Enter your age: ")

print("Hello " + name + "! You are " + age)
```

```
# If statements
is_male = False
is_tall = False

if is_male and is_tall:
  print("You are a tall male")
elif is_male and not(is_tall):
  print("You are a short male")
elif not(is_male) and is_tall:
  print("You are not a male but are tall")
else:
  print("You are not a male and not tall")
```

**Desafios Encontrados:**  
Por alguns tópicos serem mais conceitos foi um pouco difícil compreender eles de forma simples.

**Feedback e Ajustes:** 

Não houve ajustes.

**Próximos Passos:**  
Finalizar as trilhas:
- CI/CD
- Linux/Shell
- Análise de dados